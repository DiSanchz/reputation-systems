{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96879790",
   "metadata": {},
   "source": [
    "# Marketplace simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c046f999",
   "metadata": {},
   "source": [
    "### A. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b136d8",
   "metadata": {},
   "source": [
    "While non-marketplace simulations are focused on a number of consumers experiencing and leaving ratings of a single product, marketplace simulations allow to conduct a similar excercise but including a whole range of ___P___ different products from which consumers can choose between. Accordingly the journey of virtual consumers through the marketplace simulation will be in part similar to that of a non-marketplace one, with the main difference that now each of them will have to choose which particular product to buy from those available. Once this selection process takes place the consumer goes through the rest of the steps that will determine whether a rating is posted or not (formulating expectations, experiencing the product etc.). Moreover multiple marketplaces can be included in a single simulation so you can think of a marketplace simulation as being composed of ___M___ different marketplaces, including  ___P___ different simulated products each from which simulated consumers are able to choose.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169c0fdd",
   "metadata": {},
   "source": [
    "### B. Preparing the simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d826fde",
   "metadata": {},
   "source": [
    "Having briefly introduced the concept of Marketplace simulation, lets execute the following code cell containing the relevant imports to run the simulation alongside other related settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eb6c73a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext autoreload\\n%autoreload 2\\n\\n### Just a formatting related plugin\\n%load_ext nb_black\\n\\n%matplotlib inline\\nimport matplotlib.pyplot as plt\\n\\nimport sys\\nfrom numpy import random\\n\\nsys.path.append(\\\"../\\\")\\n\\n\\nimport multiprocessing as mp\\n\\nfrom collections import deque\\nfrom pathlib import Path\\nfrom typing import Dict, Optional\\n\\nimport arviz\\nimport pickle\\n\\nimport numpy as np\\nimport pandas as pd\\nimport pyreadr\\nimport sbi\\nimport sbi.utils as sbi_utils\\nimport seaborn as sns\\nimport statsmodels.formula.api as smf\\n\\nimport torch\\n\\nfrom joblib import Parallel, delayed\\nfrom matplotlib.lines import Line2D\\nfrom scipy.stats import ttest_ind\\nfrom snpe.inference import inference_class\\nfrom snpe.simulations import simulator_class\\nfrom snpe.simulations import simulator_class, marketplace_simulator_class\\nfrom snpe.embeddings.embeddings_to_ratings import EmbeddingRatingPredictor\\nfrom snpe.embeddings.embeddings_density_est_GMM import EmbeddingDensityGMM\\nfrom snpe.utils.statistics import review_histogram_correlation\\nfrom snpe.utils.tqdm_utils import tqdm_joblib\\nfrom tqdm import tqdm\\n\\nARTIFACT_PATH = Path(\\\"../artifacts/marketplace/\\\")\\n\\n### Set plotting parameters\\nsns.set(style=\\\"white\\\", context=\\\"talk\\\", font_scale=2.5)\\nsns.set_color_codes(palette=\\\"colorblind\\\")\\nsns.set_style(\\\"ticks\\\", {\\\"axes.linewidth\\\": 2.0})\";\n",
       "                var nbb_formatted_code = \"%load_ext autoreload\\n%autoreload 2\\n\\n### Just a formatting related plugin\\n%load_ext nb_black\\n\\n%matplotlib inline\\nimport matplotlib.pyplot as plt\\n\\nimport sys\\nfrom numpy import random\\n\\nsys.path.append(\\\"../\\\")\\n\\n\\nimport multiprocessing as mp\\n\\nfrom collections import deque\\nfrom pathlib import Path\\nfrom typing import Dict, Optional\\n\\nimport arviz\\nimport pickle\\n\\nimport numpy as np\\nimport pandas as pd\\nimport pyreadr\\nimport sbi\\nimport sbi.utils as sbi_utils\\nimport seaborn as sns\\nimport statsmodels.formula.api as smf\\n\\nimport torch\\n\\nfrom joblib import Parallel, delayed\\nfrom matplotlib.lines import Line2D\\nfrom scipy.stats import ttest_ind\\nfrom snpe.inference import inference_class\\nfrom snpe.simulations import simulator_class\\nfrom snpe.simulations import simulator_class, marketplace_simulator_class\\nfrom snpe.embeddings.embeddings_to_ratings import EmbeddingRatingPredictor\\nfrom snpe.embeddings.embeddings_density_est_GMM import EmbeddingDensityGMM\\nfrom snpe.utils.statistics import review_histogram_correlation\\nfrom snpe.utils.tqdm_utils import tqdm_joblib\\nfrom tqdm import tqdm\\n\\nARTIFACT_PATH = Path(\\\"../artifacts/marketplace/\\\")\\n\\n### Set plotting parameters\\nsns.set(style=\\\"white\\\", context=\\\"talk\\\", font_scale=2.5)\\nsns.set_color_codes(palette=\\\"colorblind\\\")\\nsns.set_style(\\\"ticks\\\", {\\\"axes.linewidth\\\": 2.0})\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "### Just a formatting related plugin\n",
    "%load_ext nb_black\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "from numpy import random\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "from collections import deque\n",
    "from pathlib import Path\n",
    "from typing import Dict, Optional\n",
    "\n",
    "import arviz\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyreadr\n",
    "import sbi\n",
    "import sbi.utils as sbi_utils\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import torch\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from matplotlib.lines import Line2D\n",
    "from scipy.stats import ttest_ind\n",
    "from snpe.inference import inference_class\n",
    "from snpe.simulations import simulator_class\n",
    "from snpe.simulations import simulator_class, marketplace_simulator_class\n",
    "from snpe.embeddings.embeddings_to_ratings import EmbeddingRatingPredictor\n",
    "from snpe.embeddings.embeddings_density_est_GMM import EmbeddingDensityGMM\n",
    "from snpe.utils.statistics import review_histogram_correlation\n",
    "from snpe.utils.tqdm_utils import tqdm_joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "ARTIFACT_PATH = Path(\"../artifacts/marketplace/\")\n",
    "\n",
    "### Set plotting parameters\n",
    "sns.set(style=\"white\", context=\"talk\", font_scale=2.5)\n",
    "sns.set_color_codes(palette=\"colorblind\")\n",
    "sns.set_style(\"ticks\", {\"axes.linewidth\": 2.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abd9708",
   "metadata": {},
   "source": [
    "In the cell below the path where the output of the simulation will be stored is defined. It is set such that output is stored in the \"output\" folder within this directory, but you can modify it to match your storage preferences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd004dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"OUTPUT_PATH = Path(\\\"output/\\\")\";\n",
       "                var nbb_formatted_code = \"OUTPUT_PATH = Path(\\\"output/\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "OUTPUT_PATH = Path(\"output/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24787404",
   "metadata": {},
   "source": [
    "Beyond the overall scheme presented in the introduction, markeplace simulations incorporate two other significant new elements which were not present in the non-marketplace setting and that deserve to be mentioned before actually runing the simulation.\n",
    "\n",
    "1. The first of these are the Gaussian mixture models (GMM) fitted on the products' and users' embeddings that are then used to draw the embeddings for the fictional products and users that will compose the simulated marketplaces. \n",
    "\n",
    "2. The second element is a feed-forward neural network trained to predict the real quality of each simulated product from its embedding. \n",
    "\n",
    "At this point, if you intend to run an example marketplace simulation you can just carry on with the rest of the notebook given that example data for such task is already provided. However if you are interested in running the simulation with your own data on products and users you should consider that the processes mentioned above require the following inputs:\n",
    "\n",
    "1. A file called \"productspace.tsv\" containing the 100-dimensional product embeddings, each one accompained by a product identifier in the format \"product_< id-number >\" (e.g. product_1234567). Additionally, make sure that the id-number itself does not contain any underscore itself as this may cause problem in the input processing stage.\n",
    "\n",
    "\n",
    "2. A second file \"userspace.tsv\" containing the 100-dimensional user embeddings (without any specific user identifier unlike the case of \"productspace.tsv\").\n",
    "\n",
    "\n",
    "3. A third file named \"rating_histogram_all.txt\" containing the numerical IDs and actual rating distribution [1 - 5] of the products in \"productspace.tsv\".\n",
    "\n",
    "\n",
    "For further clarity on the exact format expected for the inputs you can visit the example versions of these already provided at the path \"snpe/artifacts/marketplace/\" path within the repository. Moreover at the end of the notebook you can also find an example piece of code designed to generate valid artificial inputs for the marketplace simulation.\n",
    "\n",
    "You can place your inputs in the path \"snpe/artifacts/marketplace/\" (which is the one used by default), or alternatively select any path of your choice by setting it as the value of the argument \"artifact_path\" when instantiating the new objects of the classes in charge of fitting/training the models in the code cells below. Once the inputs have been provided as specified, the code cells below headings B.1 and B.2 can be executed to fit the GMM models for embeddings and train the feed-forward neural network for quality prediction respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5cc166",
   "metadata": {},
   "source": [
    "#### B.1 GMM model for generation of virtual products and users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83d34ae0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product embeddings of shape: (1400, 100)\n",
      "User embeddings of shape: (1400, 100)\n",
      "Fitting product model: GaussianMixture(max_iter=500, n_components=10, n_init=5, random_state=42,\n",
      "                verbose=2, verbose_interval=20)\n",
      "1260 samples in train set, 140 samples in test set\n",
      "Initialization 0\n",
      "Initialization converged: True\t time lapse 0.11376s\t ll -49.75397\n",
      "Initialization 1\n",
      "Initialization converged: True\t time lapse 0.15094s\t ll -51.00359\n",
      "Initialization 2\n",
      "Initialization converged: True\t time lapse 0.12808s\t ll -52.25830\n",
      "Initialization 3\n",
      "Initialization converged: True\t time lapse 0.14151s\t ll -50.77102\n",
      "Initialization 4\n",
      "Initialization converged: True\t time lapse 0.12490s\t ll -54.94641\n",
      "Fitting user model: GaussianMixture(max_iter=500, n_components=10, n_init=5, random_state=42,\n",
      "                verbose=2, verbose_interval=20)\n",
      "1260 samples in train set, 140 samples in test set\n",
      "Initialization 0\n",
      "Initialization converged: True\t time lapse 0.12989s\t ll -55.14327\n",
      "Initialization 1\n",
      "Initialization converged: True\t time lapse 0.12582s\t ll -51.36614\n",
      "Initialization 2\n",
      "Initialization converged: True\t time lapse 0.15564s\t ll -48.16644\n",
      "Initialization 3\n",
      "Initialization converged: True\t time lapse 0.10870s\t ll -53.98970\n",
      "Initialization 4\n",
      "Initialization converged: True\t time lapse 0.16508s\t ll -46.28597\n",
      "Training baseline models\n",
      "Initialization 0\n",
      "Initialization converged: True\t time lapse 0.04129s\t ll -84.95504\n",
      "Initialization 0\n",
      "Initialization converged: True\t time lapse 0.03472s\t ll -84.64748\n",
      "\n",
      "            Report for product embedding GMM density estimator:\n",
      "            Model score: -144.9240421564915\n",
      "            Basline score: -89.77809257799338\n",
      "            Model improvement over baseline:\n",
      "            61.42472845543127 percent\n",
      "        \n",
      "\n",
      "            Report for user embedding GMM density estimator:\n",
      "            Model score: -151.6443162126711\n",
      "            Basline score: -89.38897165964622\n",
      "            Model improvement over baseline:\n",
      "            69.64544215819573 percent\n",
      "        \n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"model = EmbeddingDensityGMM(n_components=10, n_init=5, artifact_path=ARTIFACT_PATH)\\nproduct_embeddings, user_embeddings = model.process_input_data()\\nmodel.fit(product_embeddings, user_embeddings)\\nmodel.save()\";\n",
       "                var nbb_formatted_code = \"model = EmbeddingDensityGMM(n_components=10, n_init=5, artifact_path=ARTIFACT_PATH)\\nproduct_embeddings, user_embeddings = model.process_input_data()\\nmodel.fit(product_embeddings, user_embeddings)\\nmodel.save()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = EmbeddingDensityGMM(n_components=10, n_init=5, artifact_path=ARTIFACT_PATH)\n",
    "product_embeddings, user_embeddings = model.process_input_data()\n",
    "model.fit(product_embeddings, user_embeddings)\n",
    "model.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1bb45e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### B.2 Feed-forward neural network for predicting real quality of products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db5114dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Device set to cpu, using torch num threads=8\n",
      "Using the dense network: \n",
      " Sequential(\n",
      "  (0): Linear(in_features=100, out_features=256, bias=True)\n",
      "  (1): LeakyReLU(negative_slope=0.01)\n",
      "  (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (3): LeakyReLU(negative_slope=0.01)\n",
      "  (4): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (5): LeakyReLU(negative_slope=0.01)\n",
      "  (6): Linear(in_features=64, out_features=5, bias=True)\n",
      ")\n",
      "Merged product embeddings with review histograms and produced merged DF of shape: (1400, 8)\n",
      "Train set size: torch.Size([1260]), Validation set size: torch.Size([140])\n",
      "Train Loss after epoch: 0: 33.43823054480174\n",
      "Validation loss after epoch: 0: 16.99225698198591\n",
      "Train Loss after epoch: 50: 4.440726003949604\n",
      "Validation loss after epoch: 50: 4.327787671770368\n",
      "Train Loss after epoch: 100: 3.2056250647893028\n",
      "Validation loss after epoch: 100: 5.0259086063929965\n",
      "Stopping after epoch 109 as validation loss was not improving further\n",
      "Training process has finished.\n",
      "Best loss: 2.987617083958217\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"embedding_model = EmbeddingRatingPredictor(artifact_path=ARTIFACT_PATH)\\ninput_df = embedding_model.process_input_data()\\n(\\n    ratings,\\n    embeddings,\\n    train_loader,\\n    val_loader,\\n    train_indices,\\n    val_indices,\\n) = embedding_model.create_training_data(input_df, validation_frac=0.1, batch_size=100)\\nembedding_model.fit(train_loader, val_loader, train_indices, val_indices)\\nembedding_model.save()\";\n",
       "                var nbb_formatted_code = \"embedding_model = EmbeddingRatingPredictor(artifact_path=ARTIFACT_PATH)\\ninput_df = embedding_model.process_input_data()\\n(\\n    ratings,\\n    embeddings,\\n    train_loader,\\n    val_loader,\\n    train_indices,\\n    val_indices,\\n) = embedding_model.create_training_data(input_df, validation_frac=0.1, batch_size=100)\\nembedding_model.fit(train_loader, val_loader, train_indices, val_indices)\\nembedding_model.save()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_model = EmbeddingRatingPredictor(artifact_path=ARTIFACT_PATH)\n",
    "input_df = embedding_model.process_input_data()\n",
    "(\n",
    "    ratings,\n",
    "    embeddings,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    train_indices,\n",
    "    val_indices,\n",
    ") = embedding_model.create_training_data(input_df, validation_frac=0.1, batch_size=100)\n",
    "embedding_model.fit(train_loader, val_loader, train_indices, val_indices)\n",
    "embedding_model.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9573d550",
   "metadata": {},
   "source": [
    "### C. The simulation and its arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd5b508",
   "metadata": {},
   "source": [
    "The Marketplace simulation is represented by the MarketplaceSimulator class, and its incresed complexity requires three new arguments (to be added on top of those inherited from its parent class, the HerdingSimulator class) to govern its functioning. These new arguments are:\n",
    "\n",
    "- __num_products__: Number of products to be included in each marketplace. For example, if set at a value of 1400, a total of 1400 different virtual products will be sampled from the GMM fit of the provided product embeddings for each of the simulated marketplaces. \n",
    "\n",
    "\n",
    "- __num_marketplace_reviews__: Desired number (Integer) of ratings to be obtained accross all products in a marketplace of a given to conclude the simulation. Alternatively the simulation of a marketplace will also be concluded automatically if this number of ratings has not been reached by the time that an amount of consumers 30 times larger have visited the marketplace. E.g. In a case where this argument is set to 10, if by the time 300 consumers have been simulated less than 10 ratings have been posted the simulation will be concluded automatically.\n",
    "\n",
    "\n",
    "- __consideration_set_size__: Number of virtual products (Integer) that will compose the consideration set from which the consumer will make the final purchasing decision. For instance, if set at a value of 5, consumers in the simulation will make their final purchasing decision from a set comprised of the top 5 products whose embeddings display the highest cosine similarity to their own assigned embedding.  \n",
    "\n",
    "Furthermore the MarketplaceSimulator class allows to simulate multiple different marketplaces at once. As a result of this the function of the argument 'num_simulations' which was already employed in the non-marketplace setting has been updated in accordance with the new simulational design so now it is described as:\n",
    "\n",
    "- __num_simulations__: Total number (Integer) of marketplaces to be simulated. Each marketplace will be composed of its unique set of virtual products and consumers sampled from the GMM fit of the provided product embeddings.\n",
    "\n",
    "The generate_and_save_simulations function defined below is in charge of calling the MarkeplaceSimulator class and deliver the required arguments to configure and carry out the simulation. In case you would like to re-visit the interpretations of the other arguments which are non-idiosyncratic of markeplace simulations you can scroll further  down the notebook where a brief review has been included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28e1af35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"def generate_and_save_simulations(\\n    num_simulations: int,\\n    review_prior: np.ndarray,\\n    tendency_to_rate: float,\\n    simulation_type: str,\\n    previous_rating_measure: str,\\n    min_reviews_for_herding: int,\\n    # herding_differentiating_measure: str,\\n    num_products: int,\\n    num_total_marketplace_reviews: int,\\n    consideration_set_size: int,\\n) -> None:\\n    params = {\\n        \\\"num_simulations\\\": num_simulations,\\n        \\\"review_prior\\\": review_prior,\\n        \\\"tendency_to_rate\\\": tendency_to_rate,\\n        \\\"simulation_type\\\": simulation_type,\\n        \\\"previous_rating_measure\\\": previous_rating_measure,\\n        \\\"min_reviews_for_herding\\\": min_reviews_for_herding,\\n        # \\\"herding_differentiating_measure\\\": herding_differentiating_measure,\\n        \\\"num_products\\\": num_products,\\n        \\\"num_total_marketplace_reviews\\\": num_total_marketplace_reviews,\\n        \\\"consideration_set_size\\\": consideration_set_size,\\n    }\\n    simulator = marketplace_simulator_class.MarketplaceSimulator(params)\\n    simulator.simulate(num_simulations=num_simulations)\\n    simulator.save_simulations(OUTPUT_PATH)\";\n",
       "                var nbb_formatted_code = \"def generate_and_save_simulations(\\n    num_simulations: int,\\n    review_prior: np.ndarray,\\n    tendency_to_rate: float,\\n    simulation_type: str,\\n    previous_rating_measure: str,\\n    min_reviews_for_herding: int,\\n    # herding_differentiating_measure: str,\\n    num_products: int,\\n    num_total_marketplace_reviews: int,\\n    consideration_set_size: int,\\n) -> None:\\n    params = {\\n        \\\"num_simulations\\\": num_simulations,\\n        \\\"review_prior\\\": review_prior,\\n        \\\"tendency_to_rate\\\": tendency_to_rate,\\n        \\\"simulation_type\\\": simulation_type,\\n        \\\"previous_rating_measure\\\": previous_rating_measure,\\n        \\\"min_reviews_for_herding\\\": min_reviews_for_herding,\\n        # \\\"herding_differentiating_measure\\\": herding_differentiating_measure,\\n        \\\"num_products\\\": num_products,\\n        \\\"num_total_marketplace_reviews\\\": num_total_marketplace_reviews,\\n        \\\"consideration_set_size\\\": consideration_set_size,\\n    }\\n    simulator = marketplace_simulator_class.MarketplaceSimulator(params)\\n    simulator.simulate(num_simulations=num_simulations)\\n    simulator.save_simulations(OUTPUT_PATH)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_and_save_simulations(\n",
    "    num_simulations: int,\n",
    "    review_prior: np.ndarray,\n",
    "    tendency_to_rate: float,\n",
    "    simulation_type: str,\n",
    "    previous_rating_measure: str,\n",
    "    min_reviews_for_herding: int,\n",
    "    # herding_differentiating_measure: str,\n",
    "    num_products: int,\n",
    "    num_total_marketplace_reviews: int,\n",
    "    consideration_set_size: int,\n",
    ") -> None:\n",
    "    params = {\n",
    "        \"num_simulations\": num_simulations,\n",
    "        \"review_prior\": review_prior,\n",
    "        \"tendency_to_rate\": tendency_to_rate,\n",
    "        \"simulation_type\": simulation_type,\n",
    "        \"previous_rating_measure\": previous_rating_measure,\n",
    "        \"min_reviews_for_herding\": min_reviews_for_herding,\n",
    "        # \"herding_differentiating_measure\": herding_differentiating_measure,\n",
    "        \"num_products\": num_products,\n",
    "        \"num_total_marketplace_reviews\": num_total_marketplace_reviews,\n",
    "        \"consideration_set_size\": consideration_set_size,\n",
    "    }\n",
    "    simulator = marketplace_simulator_class.MarketplaceSimulator(params)\n",
    "    simulator.simulate(num_simulations=num_simulations)\n",
    "    simulator.save_simulations(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abf4d8f",
   "metadata": {},
   "source": [
    "### D. Running the simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e524c7cf",
   "metadata": {},
   "source": [
    "After reviwing the key aspects involved in running a marketplace simulation we can proceed to run an example of it. In the code cell below the function in charge of running the simulation is called including a series of parameters that will shape it such that:\n",
    "\n",
    "1. 16 different marketplaces will be simulated.\n",
    "2. Five ratings (one for each rating value) are pre-loaded.\n",
    "3. The tendency to rate is set at 5%.\n",
    "4. It will return a timeseries of the simulated ratings.\n",
    "5. The mode (of all previous ratings) is taken as the reference metric for herding.\n",
    "6. At least five previous ratings are required for herding to start happening.\n",
    "7. Each of the simulated marketplaces will be comprised of 10 different virtual products\n",
    "8. Five ratings are required to conclude the simulation of a given marketplace.\n",
    "9. The consideration sets will be comprised of three virtual products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd64ec4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 marketplaces to be simulated on 8 CPUs. Press Enter to continue..\n",
      "Loaded product embedding density estimator: \n",
      " GaussianMixture(max_iter=500, n_components=10, n_init=5, random_state=42,\n",
      "                verbose=2, verbose_interval=20)\n",
      "Loaded user embedding density estimator: \n",
      " GaussianMixture(max_iter=500, n_components=10, n_init=5, random_state=42,\n",
      "                verbose=2, verbose_interval=20)\n",
      "\t Device set to cpu, using torch num threads=8\n",
      "Using the dense network: \n",
      " Sequential(\n",
      "  (0): Linear(in_features=100, out_features=256, bias=True)\n",
      "  (1): LeakyReLU(negative_slope=0.01)\n",
      "  (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (3): LeakyReLU(negative_slope=0.01)\n",
      "  (4): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (5): LeakyReLU(negative_slope=0.01)\n",
      "  (6): Linear(in_features=64, out_features=5, bias=True)\n",
      ")\n",
      "Loaded embedding -> rating predictor model: \n",
      " RatingPredictorModel(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=256, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.01)\n",
      "    (6): Linear(in_features=64, out_features=5, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c7e1d8a35ac430697a4389c271ba6b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Worker 1:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89b0729373e648c6af0d9ff120d68848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Worker 2:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af90caa1c5145088cedcd0c9ba00887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Worker 3:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8161d035bb424951bb20cbf2e3050304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Worker 4:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a82c85a282487f9ed94b69bdd97933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Worker 5:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "042cdabd53ba4fabada8b7d88de0b9cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Worker 6:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c31a6b7322f1430bae2e8d74910d525b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Worker 7:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffd1a7bc4dfe4556ac024aeae5f8c44a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Worker 8:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 188, in _run_module_as_main\n",
      "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 111, in _get_module_details\n",
      "    __import__(pkg_name)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/__init__.py\", line 120, in <module>\n",
      "    from .parallel import Parallel\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/parallel.py\", line 26, in <module>\n",
      "    from ._parallel_backends import (FallbackToBackend, MultiprocessingBackend,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 17, in <module>\n",
      "    from .pool import MemmappingPool\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/pool.py\", line 31, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/externals/loky/backend/popen_loky_posix.py\", line 181, in <module>\n",
      "    import argparse\n",
      "  File \"/opt/conda/lib/python3.9/argparse.py\", line 1221, in <module>\n",
      "    from ._memmapping_reducer import get_memmapping_reducers\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/_memmapping_reducer.py\", line 37, in <module>\n",
      "    class _ExtendAction(_AppendAction):\n",
      "KeyboardInterrupt\n",
      "    from .externals.loky.backend import resource_tracker\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/externals/loky/__init__.py\", line 11, in <module>\n",
      "    from .backend.context import cpu_count\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/externals/loky/backend/__init__.py\", line 4, in <module>\n",
      "    from .context import get_context\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/joblib/externals/loky/backend/context.py\", line 23, in <module>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgenerate_and_save_simulations\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtimeseries\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmode\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36mgenerate_and_save_simulations\u001b[0;34m(num_simulations, review_prior, tendency_to_rate, simulation_type, previous_rating_measure, min_reviews_for_herding, num_products, num_total_marketplace_reviews, consideration_set_size)\u001b[0m\n\u001b[1;32m     13\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_simulations\u001b[39m\u001b[38;5;124m\"\u001b[39m: num_simulations,\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreview_prior\u001b[39m\u001b[38;5;124m\"\u001b[39m: review_prior,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconsideration_set_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: consideration_set_size,\n\u001b[1;32m     24\u001b[0m }\n\u001b[1;32m     25\u001b[0m simulator \u001b[38;5;241m=\u001b[39m marketplace_simulator_class\u001b[38;5;241m.\u001b[39mMarketplaceSimulator(params)\n\u001b[0;32m---> 26\u001b[0m \u001b[43msimulator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_simulations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_simulations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m simulator\u001b[38;5;241m.\u001b[39msave_simulations(OUTPUT_PATH)\n",
      "File \u001b[0;32m/data/SUB/reputation-systems/snpe/tutorials/../snpe/simulations/marketplace_simulator_class.py:149\u001b[0m, in \u001b[0;36mMarketplaceSimulator.simulate\u001b[0;34m(self, num_simulations, num_reviews_per_simulation, simulation_parameters, existing_reviews, product_embeddings, embeddings_artifact_path, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m progproc \u001b[38;5;241m=\u001b[39m Thread(\n\u001b[1;32m    146\u001b[0m     target\u001b[38;5;241m=\u001b[39mmulti_progressbar, args\u001b[38;5;241m=\u001b[39m([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_total_marketplace_reviews \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(mp\u001b[38;5;241m.\u001b[39mcpu_count())], queue)\n\u001b[1;32m    147\u001b[0m )\n\u001b[1;32m    148\u001b[0m progproc\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m--> 149\u001b[0m simulations \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulate_marketplace\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexisting_reviews\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproduct_embeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_simulations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimulations \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(simulations)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/joblib/parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/joblib/parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 935\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    936\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/concurrent/futures/_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"generate_and_save_simulations(9, np.ones(5), 0.05, \\\"timeseries\\\", \\\"mode\\\", 5, 3, 5, 3)\";\n",
       "                var nbb_formatted_code = \"generate_and_save_simulations(9, np.ones(5), 0.05, \\\"timeseries\\\", \\\"mode\\\", 5, 3, 5, 3)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_and_save_simulations(9, np.ones(5), 0.05, \"timeseries\", \"mode\", 5, 3, 5, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7ce006",
   "metadata": {},
   "source": [
    "### Appendix 1: Review of the simulation's arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bdf3bc",
   "metadata": {},
   "source": [
    "Below you can find a review of the arguments required to carry out the simulation but that are not exclusive of the marketplace-simulations. Their functioning and interpretation is exactly the same as for non-marketplace simulations except for the 'review_prior' argument, whose interpretation differs intuitively in the sense that in does not only apply to the single product considered in a non-marketplace simulation, but to all products accross all marketplaces.\n",
    "\n",
    "- __review_prior__: Set of initial ratings for the products that are pre-loaded before the simulation starts, taking the shape of an array of five integer values. By default this is set as an array os five 1s. This implies that by the time a product within a marketplace is purchased for the first time, the consumer that has done so will observe 5 prior reviews, each of them assigned to one of the five values composing the rating scale [1 - 5]. \n",
    "\n",
    "\n",
    "- __tendency_to_rate__: Underliying tendency to rate for all consumers taking float values in the interval [0,1]. In other words, this is the proportion of consumers that will post a rating regardless of the value of the rho parameter(s) and the difference between their actual and expected product experience. If set at the default value of 0.05, 5% of all consumers will post a rating independently of the other factors at play in the simulation.This is necessary to address the \"cold start\" problem where by random chance for some products, we might have high enough values of rho that no visitors ever leave a rating.\n",
    "\n",
    "\n",
    "- __simulation_type__: Type of simulation output to produce between timeseries and histogram. Accepts the strings \"timeseries\" and \"histogram\" as inputs. Returns the timeseries of the simulated ratings, in a cumulative histogram format (so, the order of rating accumulation is preserved) if \"timeseries\" is chosen. For \"histogram\", returns the final histogram of ratings (and throws away the order of rating accumulation). \n",
    "\n",
    "\n",
    "- __previous_rating_measure__: Measure of previous ratings that will be taken as reference when experiencing herding behavior. It can be either the mean, the mode or the latest review posted. For example, if a consumer leaves a rating being subject to herding and this parameter is set as mode, it will herd towards the mode of all previous reviews. This argument is specific of the Herding and Double herding simulations and takes the strings \"mode\", \"mean\" and \"latest\" as valid inputs.\n",
    "\n",
    "\n",
    "- __min_reviews_for_herding__: Minimum number of pre-existing reviews for a consumer to be able to be subject to herding behavior. It has to be an integer value larger than 0. This argument is specific of the Herding and Double herding simulations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344cdf2a",
   "metadata": {},
   "source": [
    "### Appendix 2: Generating artificial inputs for the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c19503d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"def input_generator(\\n    number_prods: int, number_users: int, artifact_path=\\\"../artifacts/marketplace/ \\\"\\n):\\n    \\\"\\\"\\\"\\n    This function generates and saves fictional inputs for a marketplace simulation. \\n    It requires the number of products and users to include in the fictional inputs as arguments. \\n    Output is stored by default in the path \\\"snpe/artifacts/marketplace/\\\", \\n    which is the path where the instances of the marketplace simulation-related classes are instructed \\n    to look for the inputs by default.\\n    A different path storage can be provided as the value of the optional \\\"artifact_path\\\" argument. \\n    \\\"\\\"\\\"\\n    assert (\\n        number_prods < 13939\\n    ), \\\"Argument number_user cannot be set at a avalue higher than 13939\\\"\\n    ids_alone = []\\n    ids_product = []\\n\\n    # Generating a set of random product ids to be used in rating histograms and embeddings\\n    while len(ids_alone) < number_prods:\\n        a = random.randint(1000000, 9999999)\\n        if a not in ids_alone:\\n            ids_alone.append(a)\\n            ids_product.append(\\\"product_\\\" + str(a))\\n\\n    # Generating 100d arrays to be used as product embeddings\\n    hundred_space = []\\n    for i in range(number_prods):\\n        hundred_space.append(list((random.rand(100) * 2) - 1))\\n\\n    # Generating 100d arrays to be used as user embeddings\\n    hundred_space_users = []\\n    for i in range(number_users):\\n        hundred_space_users.append(list((random.rand(100) * 2) - 1))\\n\\n    # Including product ids alogside product embeddings\\n    embeddings_ready = pd.DataFrame.from_records(hundred_space)\\n    embeddings_ready.insert(0, \\\"product_id\\\", ids_product)\\n\\n    # Users have no visible id\\n    users_ready = pd.DataFrame.from_records(hundred_space_users)\\n\\n    ratings = pd.read_csv(\\\"rating_histogram_anom.txt\\\", sep=\\\"\\\\t\\\")\\n    ratings_ready = ratings.iloc[:1400]\\n    ratings_ready.insert(0, \\\"asin\\\", ids_alone)\\n\\n    embeddings_ready.to_csv(\\n        str(artifact_path) + \\\"productspace.tsv\\\", sep=\\\"\\\\t\\\", index=False, header=False\\n    )\\n    users_ready.to_csv(\\n        str(artifact_path) + \\\"userspace.tsv\\\", sep=\\\"\\\\t\\\", index=False, header=False\\n    )\\n    ratings_ready.to_csv(\\n        str(artifact_path) + \\\"rating_histogram_all.txt\\\", sep=\\\"\\\\t\\\", index=False\\n    )\";\n",
       "                var nbb_formatted_code = \"def input_generator(\\n    number_prods: int, number_users: int, artifact_path=\\\"../artifacts/marketplace/ \\\"\\n):\\n    \\\"\\\"\\\"\\n    This function generates and saves fictional inputs for a marketplace simulation. \\n    It requires the number of products and users to include in the fictional inputs as arguments. \\n    Output is stored by default in the path \\\"snpe/artifacts/marketplace/\\\", \\n    which is the path where the instances of the marketplace simulation-related classes are instructed \\n    to look for the inputs by default.\\n    A different path storage can be provided as the value of the optional \\\"artifact_path\\\" argument. \\n    \\\"\\\"\\\"\\n    assert (\\n        number_prods < 13939\\n    ), \\\"Argument number_user cannot be set at a avalue higher than 13939\\\"\\n    ids_alone = []\\n    ids_product = []\\n\\n    # Generating a set of random product ids to be used in rating histograms and embeddings\\n    while len(ids_alone) < number_prods:\\n        a = random.randint(1000000, 9999999)\\n        if a not in ids_alone:\\n            ids_alone.append(a)\\n            ids_product.append(\\\"product_\\\" + str(a))\\n\\n    # Generating 100d arrays to be used as product embeddings\\n    hundred_space = []\\n    for i in range(number_prods):\\n        hundred_space.append(list((random.rand(100) * 2) - 1))\\n\\n    # Generating 100d arrays to be used as user embeddings\\n    hundred_space_users = []\\n    for i in range(number_users):\\n        hundred_space_users.append(list((random.rand(100) * 2) - 1))\\n\\n    # Including product ids alogside product embeddings\\n    embeddings_ready = pd.DataFrame.from_records(hundred_space)\\n    embeddings_ready.insert(0, \\\"product_id\\\", ids_product)\\n\\n    # Users have no visible id\\n    users_ready = pd.DataFrame.from_records(hundred_space_users)\\n\\n    ratings = pd.read_csv(\\\"rating_histogram_anom.txt\\\", sep=\\\"\\\\t\\\")\\n    ratings_ready = ratings.iloc[:1400]\\n    ratings_ready.insert(0, \\\"asin\\\", ids_alone)\\n\\n    embeddings_ready.to_csv(\\n        str(artifact_path) + \\\"productspace.tsv\\\", sep=\\\"\\\\t\\\", index=False, header=False\\n    )\\n    users_ready.to_csv(\\n        str(artifact_path) + \\\"userspace.tsv\\\", sep=\\\"\\\\t\\\", index=False, header=False\\n    )\\n    ratings_ready.to_csv(\\n        str(artifact_path) + \\\"rating_histogram_all.txt\\\", sep=\\\"\\\\t\\\", index=False\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def input_generator(\n",
    "    number_prods: int, number_users: int, artifact_path=\"../artifacts/marketplace/ \"\n",
    "):\n",
    "    \"\"\"\n",
    "    This function generates and saves fictional inputs for a marketplace simulation. \n",
    "    It requires the number of products and users to include in the fictional inputs as arguments. \n",
    "    Output is stored by default in the path \"snpe/artifacts/marketplace/\", \n",
    "    which is the path where the instances of the marketplace simulation-related classes are instructed \n",
    "    to look for the inputs by default.\n",
    "    A different path storage can be provided as the value of the optional \"artifact_path\" argument. \n",
    "    \"\"\"\n",
    "    assert (\n",
    "        number_prods < 13939\n",
    "    ), \"Argument number_user cannot be set at a avalue higher than 13939\"\n",
    "    ids_alone = []\n",
    "    ids_product = []\n",
    "\n",
    "    # Generating a set of random product ids to be used in rating histograms and embeddings\n",
    "    while len(ids_alone) < number_prods:\n",
    "        a = random.randint(1000000, 9999999)\n",
    "        if a not in ids_alone:\n",
    "            ids_alone.append(a)\n",
    "            ids_product.append(\"product_\" + str(a))\n",
    "\n",
    "    # Generating 100d arrays to be used as product embeddings\n",
    "    hundred_space = []\n",
    "    for i in range(number_prods):\n",
    "        hundred_space.append(list((random.rand(100) * 2) - 1))\n",
    "\n",
    "    # Generating 100d arrays to be used as user embeddings\n",
    "    hundred_space_users = []\n",
    "    for i in range(number_users):\n",
    "        hundred_space_users.append(list((random.rand(100) * 2) - 1))\n",
    "\n",
    "    # Including product ids alogside product embeddings\n",
    "    embeddings_ready = pd.DataFrame.from_records(hundred_space)\n",
    "    embeddings_ready.insert(0, \"product_id\", ids_product)\n",
    "\n",
    "    # Users have no visible id\n",
    "    users_ready = pd.DataFrame.from_records(hundred_space_users)\n",
    "\n",
    "    ratings = pd.read_csv(\"rating_histogram_anom.txt\", sep=\"\\t\")\n",
    "    ratings_ready = ratings.iloc[:1400]\n",
    "    ratings_ready.insert(0, \"asin\", ids_alone)\n",
    "\n",
    "    embeddings_ready.to_csv(\n",
    "        str(artifact_path) + \"productspace.tsv\", sep=\"\\t\", index=False, header=False\n",
    "    )\n",
    "    users_ready.to_csv(\n",
    "        str(artifact_path) + \"userspace.tsv\", sep=\"\\t\", index=False, header=False\n",
    "    )\n",
    "    ratings_ready.to_csv(\n",
    "        str(artifact_path) + \"rating_histogram_all.txt\", sep=\"\\t\", index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6b93e9",
   "metadata": {},
   "source": [
    "Genrating artificial output containing 1400 fictional products and users to feed the GMM models and the neural network from B.1 and B.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f437d6df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"input_generator(1400, 1400)\";\n",
       "                var nbb_formatted_code = \"input_generator(1400, 1400)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_generator(1400, 1400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
