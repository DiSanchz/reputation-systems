{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96879790",
   "metadata": {},
   "source": [
    "# Marketplace simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c046f999",
   "metadata": {},
   "source": [
    "### A. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b136d8",
   "metadata": {},
   "source": [
    "While non-marketplace simulations are focused on a number of consumers experiencing and leaving ratings of a single product, marketplace simulations allow to conduct a similar excercise but including a whole range of ___P___ different products from which consumers can choose between. Accordingly the journey of virtual consumers through the marketplace simulation will be in part similar to that of a non-marketplace one, with the main difference that now each of them will have to choose which particular product to buy from those available. Once this selection process takes place the consumer goes through the rest of the steps that will determine whether a rating is posted or not (formulating expectations, experiencing the product etc.). Moreover multiple marketplaces can be included in a single simulation so you can think of a marketplace simulation as being composed of ___M___ different marketplaces, including  ___P___ different simulated products each from which simulated consumers are able to choose.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169c0fdd",
   "metadata": {},
   "source": [
    "### B. Preparing the simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d826fde",
   "metadata": {},
   "source": [
    "Having briefly introduced the concept of Marketplace simulation, lets execute the following code cell containing the relevant imports to run the simulation alongside other elated settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eb6c73a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 1;\n                var nbb_unformatted_code = \"%load_ext autoreload\\n%autoreload 2\\n\\n### Just a formatting related plugin\\n%load_ext nb_black\\n\\n%matplotlib inline\\nimport matplotlib.pyplot as plt\\n\\nimport sys\\n\\nsys.path.append(\\\"../\\\")\\n\\nimport multiprocessing as mp\\n\\nfrom collections import deque\\nfrom pathlib import Path\\nfrom typing import Dict, Optional\\n\\nimport arviz\\nimport pickle\\n\\nimport numpy as np\\nimport pandas as pd\\nimport pyreadr\\nimport sbi\\nimport sbi.utils as sbi_utils\\nimport seaborn as sns\\nimport statsmodels.formula.api as smf\\n\\nimport torch\\n\\nfrom joblib import Parallel, delayed\\nfrom matplotlib.lines import Line2D\\nfrom scipy.stats import ttest_ind\\nfrom snpe.inference import inference_class\\nfrom snpe.simulations import simulator_class\\nfrom snpe.simulations import simulator_class, marketplace_simulator_class\\nfrom snpe.embeddings.embeddings_to_ratings import EmbeddingRatingPredictor\\nfrom snpe.embeddings.embeddings_density_est_GMM import EmbeddingDensityGMM\\nfrom snpe.utils.statistics import review_histogram_correlation\\nfrom snpe.utils.tqdm_utils import tqdm_joblib\\nfrom tqdm import tqdm\\n\\n### Set plotting parameters\\nsns.set(style=\\\"white\\\", context=\\\"talk\\\", font_scale=2.5)\\nsns.set_color_codes(palette=\\\"colorblind\\\")\\nsns.set_style(\\\"ticks\\\", {\\\"axes.linewidth\\\": 2.0})\";\n                var nbb_formatted_code = \"%load_ext autoreload\\n%autoreload 2\\n\\n### Just a formatting related plugin\\n%load_ext nb_black\\n\\n%matplotlib inline\\nimport matplotlib.pyplot as plt\\n\\nimport sys\\n\\nsys.path.append(\\\"../\\\")\\n\\nimport multiprocessing as mp\\n\\nfrom collections import deque\\nfrom pathlib import Path\\nfrom typing import Dict, Optional\\n\\nimport arviz\\nimport pickle\\n\\nimport numpy as np\\nimport pandas as pd\\nimport pyreadr\\nimport sbi\\nimport sbi.utils as sbi_utils\\nimport seaborn as sns\\nimport statsmodels.formula.api as smf\\n\\nimport torch\\n\\nfrom joblib import Parallel, delayed\\nfrom matplotlib.lines import Line2D\\nfrom scipy.stats import ttest_ind\\nfrom snpe.inference import inference_class\\nfrom snpe.simulations import simulator_class\\nfrom snpe.simulations import simulator_class, marketplace_simulator_class\\nfrom snpe.embeddings.embeddings_to_ratings import EmbeddingRatingPredictor\\nfrom snpe.embeddings.embeddings_density_est_GMM import EmbeddingDensityGMM\\nfrom snpe.utils.statistics import review_histogram_correlation\\nfrom snpe.utils.tqdm_utils import tqdm_joblib\\nfrom tqdm import tqdm\\n\\n### Set plotting parameters\\nsns.set(style=\\\"white\\\", context=\\\"talk\\\", font_scale=2.5)\\nsns.set_color_codes(palette=\\\"colorblind\\\")\\nsns.set_style(\\\"ticks\\\", {\\\"axes.linewidth\\\": 2.0})\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "### Just a formatting related plugin\n",
    "%load_ext nb_black\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "from collections import deque\n",
    "from pathlib import Path\n",
    "from typing import Dict, Optional\n",
    "\n",
    "import arviz\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyreadr\n",
    "import sbi\n",
    "import sbi.utils as sbi_utils\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import torch\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from matplotlib.lines import Line2D\n",
    "from scipy.stats import ttest_ind\n",
    "from snpe.inference import inference_class\n",
    "from snpe.simulations import simulator_class\n",
    "from snpe.simulations import simulator_class, marketplace_simulator_class\n",
    "from snpe.embeddings.embeddings_to_ratings import EmbeddingRatingPredictor\n",
    "from snpe.embeddings.embeddings_density_est_GMM import EmbeddingDensityGMM\n",
    "from snpe.utils.statistics import review_histogram_correlation\n",
    "from snpe.utils.tqdm_utils import tqdm_joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "### Set plotting parameters\n",
    "sns.set(style=\"white\", context=\"talk\", font_scale=2.5)\n",
    "sns.set_color_codes(palette=\"colorblind\")\n",
    "sns.set_style(\"ticks\", {\"axes.linewidth\": 2.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abd9708",
   "metadata": {},
   "source": [
    "In the cell below the path where the output of the simulation will be stored is defined, you can modify it to match your storage preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd004dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 2;\n                var nbb_unformatted_code = \"ARTIFACT_PATH = Path(\\\"../../../\\\")\";\n                var nbb_formatted_code = \"ARTIFACT_PATH = Path(\\\"../../../\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ARTIFACT_PATH = Path(\"../../../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b21f40f",
   "metadata": {},
   "source": [
    "Another option to adjust is the number of CPUs involved in the simulation. The cell below is set so all the CPUs available are employed in the simulation. (Note: The MarketplaceSimulator class, which is in charge of the simulation, is designed to paralellize the simulation of the different marketplaces across all the CPUs to be employed.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59f5405e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 3;\n                var nbb_unformatted_code = \"torch.set_num_threads(mp.cpu_count())\\ntorch.get_num_threads()\";\n                var nbb_formatted_code = \"torch.set_num_threads(mp.cpu_count())\\ntorch.get_num_threads()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.set_num_threads(mp.cpu_count())\n",
    "torch.get_num_threads()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24787404",
   "metadata": {},
   "source": [
    "Beyond the overall scheme presented in the introduction, markeplace simulations incorporate two other significant new elements which were not present in the non-marketplace setting and that deserve to be mentioned before actually runing the simulation. The first of these are the Gaussian mixture models (GMM) fitted on the products' and users' embeddings that are then used to draw the embeddings for the fictional products and users that will compose the simulated marketplaces. The second element is a feed-forward neural network trained to predict the real quality of each simulated product from its embedding. \n",
    "\n",
    "At this point, if you intend to run an example marketplace simulation you can just carry on with the rest of the notebook given that example data for such task is already provided. However if you are interested in running the simulation with your own data on products and users you should consider that the processes mentioned above require the following inputs:\n",
    "\n",
    "1. A file called \"productspace.tsv\" containing the 100-dimensional product embeddings, each one accompained by a product identifier in the format \"product_< id >\" where the id is a 7 digit number (e.g. product_1234567)\n",
    "\n",
    "\n",
    "2. A second file \"userspace.tsv\" containing the 100-dimensional user embeddings (without any specific user identifier unlike the case of \"productspace.tsv\").\n",
    "\n",
    "\n",
    "3. A third file named \"rating_histogram_all.txt\" containing the numerical IDs and actual rating distribution [1 - 5] of the products in \"productspace.tsv\".\n",
    "\n",
    "\n",
    "These files need to be placed in the \"snpe/artifacts/marketplace/\" path within the repository. For further clarity on the exact format expected for the inputs you can visit the example versions of these already provided at the aforementioned path. Once the inputs have been provided as specified the code cells below headings B.1 and B.2 can be executed to fit the GMM models for embeddings and train the feed-forward neural network for quality prediction respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5cc166",
   "metadata": {},
   "source": [
    "#### B.1 GMM model for generation of virtual products and users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83d34ae0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product embeddings of shape: (1400, 100)\n",
      "User embeddings of shape: (1400, 100)\n",
      "Fitting product model: GaussianMixture(max_iter=500, n_components=10, n_init=5, random_state=42,\n",
      "                verbose=2, verbose_interval=20)\n",
      "1260 samples in train set, 140 samples in test set\n",
      "Initialization 0\n",
      "Initialization converged: True\t time lapse 0.25611s\t ll -47.48063\n",
      "Initialization 1\n",
      "Initialization converged: True\t time lapse 0.23629s\t ll -53.74126\n",
      "Initialization 2\n",
      "Initialization converged: True\t time lapse 0.18341s\t ll -53.24265\n",
      "Initialization 3\n",
      "Initialization converged: True\t time lapse 0.17834s\t ll -54.57947\n",
      "Initialization 4\n",
      "Initialization converged: True\t time lapse 0.19672s\t ll -47.80314\n",
      "Fitting user model: GaussianMixture(max_iter=500, n_components=10, n_init=5, random_state=42,\n",
      "                verbose=2, verbose_interval=20)\n",
      "1260 samples in train set, 140 samples in test set\n",
      "Initialization 0\n",
      "Initialization converged: True\t time lapse 0.19411s\t ll -47.15143\n",
      "Initialization 1\n",
      "Initialization converged: True\t time lapse 0.18714s\t ll -55.74038\n",
      "Initialization 2\n",
      "Initialization converged: True\t time lapse 0.20780s\t ll -56.03623\n",
      "Initialization 3\n",
      "Initialization converged: True\t time lapse 0.19551s\t ll -46.07696\n",
      "Initialization 4\n",
      "Initialization converged: True\t time lapse 0.18720s\t ll -52.91316\n",
      "Training baseline models\n",
      "Initialization 0\n",
      "Initialization converged: True\t time lapse 0.09124s\t ll -84.92306\n",
      "Initialization 0\n",
      "Initialization converged: True\t time lapse 0.02698s\t ll -84.98162\n",
      "\n",
      "            Report for product embedding GMM density estimator:\n",
      "            Model score: -152.36949262141283\n",
      "            Basline score: -90.05706665855003\n",
      "            Model improvement over baseline:\n",
      "            69.19215590167889 percent\n",
      "        \n",
      "\n",
      "            Report for user embedding GMM density estimator:\n",
      "            Model score: -157.1864472632693\n",
      "            Basline score: -89.38320109299966\n",
      "            Model improvement over baseline:\n",
      "            75.8568112812642 percent\n",
      "        \n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 4;\n                var nbb_unformatted_code = \"model = EmbeddingDensityGMM(n_components=10, n_init=5)\\nproduct_embeddings, user_embeddings = model.process_input_data()\\nmodel.fit(product_embeddings, user_embeddings)\\nmodel.save()\";\n                var nbb_formatted_code = \"model = EmbeddingDensityGMM(n_components=10, n_init=5)\\nproduct_embeddings, user_embeddings = model.process_input_data()\\nmodel.fit(product_embeddings, user_embeddings)\\nmodel.save()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = EmbeddingDensityGMM(n_components=10, n_init=5)\n",
    "product_embeddings, user_embeddings = model.process_input_data()\n",
    "model.fit(product_embeddings, user_embeddings)\n",
    "model.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1bb45e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### B.2 Feed-forward neural network for predicting real quality of products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db5114dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Device set to cpu, using torch num threads=8\n",
      "Using the dense network: \n",
      " Sequential(\n",
      "  (0): Linear(in_features=100, out_features=256, bias=True)\n",
      "  (1): LeakyReLU(negative_slope=0.01)\n",
      "  (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (3): LeakyReLU(negative_slope=0.01)\n",
      "  (4): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (5): LeakyReLU(negative_slope=0.01)\n",
      "  (6): Linear(in_features=64, out_features=5, bias=True)\n",
      ")\n",
      "Merged product embeddings with review histograms and produced merged DF of shape: (1400, 8)\n",
      "Train set size: torch.Size([1260]), Validation set size: torch.Size([140])\n",
      "Train Loss after epoch: 0: 35.938887823195685\n",
      "Validation loss after epoch: 0: 22.670989717755997\n",
      "Train Loss after epoch: 50: 4.288715635027204\n",
      "Validation loss after epoch: 50: 5.013527529580252\n",
      "Stopping after epoch 76 as validation loss was not improving further\n",
      "Training process has finished.\n",
      "Best loss: 3.7975120544433594\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 5;\n                var nbb_unformatted_code = \"embedding_model = EmbeddingRatingPredictor()\\ninput_df = embedding_model.process_input_data()\\n(ratings,embeddings,train_loader,val_loader,train_indices,val_indices,) = embedding_model.create_training_data(input_df, validation_frac=0.1, batch_size=100)\\nembedding_model.fit(train_loader, val_loader, train_indices, val_indices)\\nembedding_model.save()\";\n                var nbb_formatted_code = \"embedding_model = EmbeddingRatingPredictor()\\ninput_df = embedding_model.process_input_data()\\n(\\n    ratings,\\n    embeddings,\\n    train_loader,\\n    val_loader,\\n    train_indices,\\n    val_indices,\\n) = embedding_model.create_training_data(input_df, validation_frac=0.1, batch_size=100)\\nembedding_model.fit(train_loader, val_loader, train_indices, val_indices)\\nembedding_model.save()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_model = EmbeddingRatingPredictor()\n",
    "input_df = embedding_model.process_input_data()\n",
    "(\n",
    "    ratings,\n",
    "    embeddings,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    train_indices,\n",
    "    val_indices,\n",
    ") = embedding_model.create_training_data(input_df, validation_frac=0.1, batch_size=100)\n",
    "embedding_model.fit(train_loader, val_loader, train_indices, val_indices)\n",
    "embedding_model.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9573d550",
   "metadata": {},
   "source": [
    "### C. The simulation and its arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd5b508",
   "metadata": {},
   "source": [
    "The Marketplace simulation is represented by the MarketplaceSimulator class, and its increased complexity requires three new arguments (to be added on top of those inherited from its parent class, the HerdingSimulator class) to govern its functioning. These new arguments are:\n",
    "\n",
    "- __num_products__: Number of products to be included in each marketplace. For example, if set at a value of 1400, a total of 1400 different virtual products will be sampled from the GMM fit of the provided product embeddings for each of the simulated marketplaces. \n",
    "\n",
    "\n",
    "- __num_marketplace_reviews__: Desired number (Integer) of ratings to be obtained to conclude the simulation of each marketplace. Alternatively the simulation of a marketplace will also be concluded automatically if this number of ratings has not been reached by the time that an amount of consumers 30 times larger have visited the marketplace. E.g. In a case where this argument is set to 10, if by the time 300 consumers have been simulated less than 10 ratings have been posted the simulation will be concluded automatically.\n",
    "\n",
    "\n",
    "- __consideration_set_size__: Number of virtual products (Integer) that will compose the consideration set from which the consumer will make the final purchasing decision. For instance, if set at a value of 5, consumers in the simulation will make their final purchasing decision from a set comprised of the top 5 products whose embeddings display the highest cosine similarity to their own assigned embedding.  \n",
    "\n",
    "Furthermore the MarketplaceSimulator class allows to simulate multiple different marketplaces at once. As a result of this the function of the argument 'num_simulations' which was already employed in the non-marketplace setting has been updated in accordance with the new simulational design so now it is described as:\n",
    "\n",
    "- __num_simulations__: Total number (Integer) of marketplaces to be simulated. Each marketplace will be composed of its unique set of virtual products and consumers sampled from the GMM fit of the provided product embeddings.\n",
    "\n",
    "The generate_and_save_simulations function defined below is in charge of calling the MarkeplaceSimulator class and deliver the required arguments to configure and carry out the simulation. In case you would like to re-visit the interpretations the meaning of the other arguments which are non-idiosyncratic of markeplace simulations you can scroll down to the end of the notebook where a brief review has been included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28e1af35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 6;\n                var nbb_unformatted_code = \"def generate_and_save_simulations(\\n    num_simulations: int,\\n    review_prior: np.ndarray,\\n    tendency_to_rate: float,\\n    simulation_type: str,\\n    previous_rating_measure: str,\\n    min_reviews_for_herding: int,\\n    # herding_differentiating_measure: str,\\n    num_products: int,\\n    num_total_marketplace_reviews: int,\\n    consideration_set_size: int,\\n) -> None:\\n    params = {\\n        \\\"num_simulations\\\": num_simulations,\\n        \\\"review_prior\\\": review_prior,\\n        \\\"tendency_to_rate\\\": tendency_to_rate,\\n        \\\"simulation_type\\\": simulation_type,\\n        \\\"previous_rating_measure\\\": previous_rating_measure,\\n        \\\"min_reviews_for_herding\\\": min_reviews_for_herding,\\n        # \\\"herding_differentiating_measure\\\": herding_differentiating_measure,\\n        \\\"num_products\\\": num_products,\\n        \\\"num_total_marketplace_reviews\\\": num_total_marketplace_reviews,\\n        \\\"consideration_set_size\\\": consideration_set_size,\\n    }\\n    simulator = marketplace_simulator_class.MarketplaceSimulator(params)\\n    simulator.simulate(num_simulations=num_simulations)\\n    simulator.save_simulations(ARTIFACT_PATH)\";\n                var nbb_formatted_code = \"def generate_and_save_simulations(\\n    num_simulations: int,\\n    review_prior: np.ndarray,\\n    tendency_to_rate: float,\\n    simulation_type: str,\\n    previous_rating_measure: str,\\n    min_reviews_for_herding: int,\\n    # herding_differentiating_measure: str,\\n    num_products: int,\\n    num_total_marketplace_reviews: int,\\n    consideration_set_size: int,\\n) -> None:\\n    params = {\\n        \\\"num_simulations\\\": num_simulations,\\n        \\\"review_prior\\\": review_prior,\\n        \\\"tendency_to_rate\\\": tendency_to_rate,\\n        \\\"simulation_type\\\": simulation_type,\\n        \\\"previous_rating_measure\\\": previous_rating_measure,\\n        \\\"min_reviews_for_herding\\\": min_reviews_for_herding,\\n        # \\\"herding_differentiating_measure\\\": herding_differentiating_measure,\\n        \\\"num_products\\\": num_products,\\n        \\\"num_total_marketplace_reviews\\\": num_total_marketplace_reviews,\\n        \\\"consideration_set_size\\\": consideration_set_size,\\n    }\\n    simulator = marketplace_simulator_class.MarketplaceSimulator(params)\\n    simulator.simulate(num_simulations=num_simulations)\\n    simulator.save_simulations(ARTIFACT_PATH)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_and_save_simulations(\n",
    "    num_simulations: int,\n",
    "    review_prior: np.ndarray,\n",
    "    tendency_to_rate: float,\n",
    "    simulation_type: str,\n",
    "    previous_rating_measure: str,\n",
    "    min_reviews_for_herding: int,\n",
    "    # herding_differentiating_measure: str,\n",
    "    num_products: int,\n",
    "    num_total_marketplace_reviews: int,\n",
    "    consideration_set_size: int,\n",
    ") -> None:\n",
    "    params = {\n",
    "        \"num_simulations\": num_simulations,\n",
    "        \"review_prior\": review_prior,\n",
    "        \"tendency_to_rate\": tendency_to_rate,\n",
    "        \"simulation_type\": simulation_type,\n",
    "        \"previous_rating_measure\": previous_rating_measure,\n",
    "        \"min_reviews_for_herding\": min_reviews_for_herding,\n",
    "        # \"herding_differentiating_measure\": herding_differentiating_measure,\n",
    "        \"num_products\": num_products,\n",
    "        \"num_total_marketplace_reviews\": num_total_marketplace_reviews,\n",
    "        \"consideration_set_size\": consideration_set_size,\n",
    "    }\n",
    "    simulator = marketplace_simulator_class.MarketplaceSimulator(params)\n",
    "    simulator.simulate(num_simulations=num_simulations)\n",
    "    simulator.save_simulations(ARTIFACT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abf4d8f",
   "metadata": {},
   "source": [
    "### D. Running the simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e524c7cf",
   "metadata": {},
   "source": [
    "After reviwing the key aspects involved in running a marketplace simulation we can proceed to run an example of it. In the code cell below the function in charge of running the simulation is called including a series of parameters that will shape it such that:\n",
    "\n",
    "1. 16 different marketplaces will be simulated.\n",
    "2. Five ratings (one for each rating value) are pre-loaded.\n",
    "3. The tendency to rate is set at 5%.\n",
    "4. It will return a timeseries of the simulated ratings.\n",
    "5. The mode (of all previous ratings) is taken as the reference metric for herding.\n",
    "6. At least five previous ratings are required for herding to start happening.\n",
    "7. Each of the simulated marketplaces will be comprised of 10 different virtual products\n",
    "8. Five ratings are required to conclude the simulation of a given marketplace.\n",
    "9. The consideration sets will be comprised of three virtual products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd64ec4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 marketplaces to be simulated on 8 CPUs. Press Enter to continue..\n",
      "Loaded product embedding density estimator: \n",
      " GaussianMixture(max_iter=500, n_components=10, n_init=5, random_state=42,\n",
      "                verbose=2, verbose_interval=20)\n",
      "Loaded user embedding density estimator: \n",
      " GaussianMixture(max_iter=500, n_components=10, n_init=5, random_state=42,\n",
      "                verbose=2, verbose_interval=20)\n",
      "\t Device set to cpu, using torch num threads=8\n",
      "Using the dense network: \n",
      " Sequential(\n",
      "  (0): Linear(in_features=100, out_features=256, bias=True)\n",
      "  (1): LeakyReLU(negative_slope=0.01)\n",
      "  (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (3): LeakyReLU(negative_slope=0.01)\n",
      "  (4): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (5): LeakyReLU(negative_slope=0.01)\n",
      "  (6): Linear(in_features=64, out_features=5, bias=True)\n",
      ")\n",
      "Loaded embedding -> rating predictor model: \n",
      " RatingPredictorModel(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=256, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.01)\n",
      "    (6): Linear(in_features=64, out_features=5, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2afb4d61d46240ff8cd802dcad5d9748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Worker 1:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "539dc3fed9744eff96fb95679bc6661b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Worker 2:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70aaa18d61c748b89e81f4a7fe28180f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Worker 3:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b0f1df309d4b87907944a4294f3e96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Worker 4:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1527234e2d3549cbbcc65c7f470b0e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Worker 5:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "154989fd956b47f7a879235febd22f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Worker 6:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf554ecbbfe432791c513bef98f30f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Worker 7:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "427190948a0f4dba908fc14b0c347878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Worker 8:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 7;\n                var nbb_unformatted_code = \"generate_and_save_simulations(16, np.ones(5), 0.05, \\\"timeseries\\\", \\\"mode\\\", 5, 10, 5, 3)\";\n                var nbb_formatted_code = \"generate_and_save_simulations(16, np.ones(5), 0.05, \\\"timeseries\\\", \\\"mode\\\", 5, 10, 5, 3)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_and_save_simulations(16, np.ones(5), 0.05, \"timeseries\", \"mode\", 5, 10, 5, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7ce006",
   "metadata": {},
   "source": [
    "### E. Review of the simulation's arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bdf3bc",
   "metadata": {},
   "source": [
    "Below you can find a review of the arguments required to carry out the simulation but that are not exclusive of the marketplace-simulations. Their functioning and interpretation is exactly the same as for non-marketplace simulations except for the 'review_prior' argument, whose interpretation differs intuitively in the sense that in does not only apply to the single product considered in a non-marketplace simulation, but to all products accross all marketplaces.\n",
    "\n",
    "- __review_prior__: Set of initial ratings for the products that are pre-loaded before the simulation starts, taking the shape of an array of five integer values. By default this is set as an array os five 1s. This implies that by the time a product within a marketplace is purchased for the first time, the consumer that has done so will observe 5 prior reviews, each of them assigned to one of the five values composing the rating scale [1 - 5]. \n",
    "\n",
    "\n",
    "- __tendency_to_rate__: Underliying tendency to rate for all consumers taking float values in the interval [0,1]. In other words, this is the proportion of consumers that will post a rating regardless of the value of the rho parameter(s) and the difference between their actual and expected product experience. If set at the default value of 0.05, 5% of all consumers will post a rating independently of the other factors at play in the simulation.This is necessary to address the \"cold start\" problem where by random chance for some products, we might have high enough values of rho that no visitors ever leave a rating.\n",
    "\n",
    "\n",
    "- __simulation_type__: Type of simulation output to produce between timeseries and histogram. Accepts the strings \"timeseries\" and \"histogram\" as inputs. Returns the timeseries of the simulated ratings, in a cumulative histogram format (so, the order of rating accumulation is preserved) if \"timeseries\" is chosen. For \"histogram\", returns the final histogram of ratings (and throws away the order of rating accumulation). \n",
    "\n",
    "\n",
    "- __previous_rating_measure__: Measure of previous ratings that will be taken as reference when experiencing herding behavior. It can be either the mean, the mode or the latest review posted. For example, if a consumer leaves a rating being subject to herding and this parameter is set as mode, it will herd towards the mode of all previous reviews. This argument is specific of the Herding and Double herding simulations and takes the strings \"mode\", \"mean\" and \"latest\" as valid inputs.\n",
    "\n",
    "\n",
    "- __min_reviews_for_herding__: Minimum number of pre-existing reviews for a consumer to be able to be subject to herding behavior. It has to be an integer value larger than 0. This argument is specific of the Herding and Double herding simulations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
